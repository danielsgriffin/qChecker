---
filename: "2310.14724.pdf"
---
"it facilitates the detection process through efficient, open-source algorithms"
"Such an approach yields watermarks that are challenging to eliminate, even when the model undergoes fine-tuning across various downstream tasks."
"Additionally, fine-tuning LMs classifiers is limited in facing data generated by different models [133]."
"There is an imperative demand for robust detectors to identify LLM-generated text effectively. Establishing such mechanisms is pivotal to mitigating LLM misuse risks and fostering responsible AI governance in the LLM era."
"If used improperly, these models have the potential to diminish linguistic diversity and contribute to the formation of information silos within societal discourse."
"However, for the LLM-generated text detection task, detection methods relying on humans are unreliable, and have very low accuracy, even only slightly better than random classification."
"Although current methodologies may have limitations, further enhancements in detection capabilities will strengthen academic integrity and preserve human independent thinking in scientific research."
"The detector techniques have witnessed notable advancements recently, propelled by innovations in watermarking techniques, zero-shot methods, fine-tuning LMs methods, adversarial learning methods, LLMs as detectors, and human-assisted methods."
"Contemporary detectors designed for LLM-generated text primarily target monolingual applications, often neglecting to evaluate and optimize performance across multiple languages."
"The threat of prompt attacks will be further amplified in the future with the research on prompt engineering."
"There exists the risk of malicious exploitation of LLMs in activities such as disinformation dissemination, online fraudulent schemes, social media spam production, and academic dishonesty."



